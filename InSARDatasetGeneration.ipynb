{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a67c03-afbd-4eb0-a3fc-338f32adbf41",
   "metadata": {},
   "source": [
    "# 1. Generating InSAR Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7610f358-c488-4391-89e1-f8ad76a65788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac82bd6-47e4-4e3f-9352-42f936019bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Noise2NoiseDataset(Dataset):\n",
    "    def __init__(self, size, S_max=5.0, D=50, nu=0.25, cm=1.0, V=1.0,\n",
    "                 random_noise_std=0.56, tropospheric_noise_beta=1.82, tropospheric_noise_scale=1.0,\n",
    "                 total_days=1460, interval_days=49, f_t=-1, orbit_type='ascending'):\n",
    "        self.size = size\n",
    "        self.S_max = S_max\n",
    "        self.D = D\n",
    "        self.nu = nu\n",
    "        self.cm = cm\n",
    "        self.V = V\n",
    "        self.random_noise_std = random_noise_std\n",
    "        self.tropospheric_noise_beta = tropospheric_noise_beta\n",
    "        self.tropospheric_noise_scale = tropospheric_noise_scale\n",
    "        self.total_days = total_days\n",
    "        self.interval_days = interval_days\n",
    "        self.f_t = f_t\n",
    "        self.orbit_type = orbit_type\n",
    "\n",
    "        self.incidence_angle_deg, self.satellite_azimuth_deg = self._get_orbit_geometry()\n",
    "        self.times = self.get_times()\n",
    "        \n",
    "        if len(self.times) == 0:\n",
    "            self.total_time = 1.0\n",
    "        elif len(self.times) == 1:\n",
    "             self.total_time = self.times[0] if self.times[0] > 0 else 1.0\n",
    "        else:\n",
    "            self.total_time = self.times[-1] if self.times[-1] > 0 else 1.0\n",
    "        if self.total_time <=0: self.total_time = 1.0\n",
    "\n",
    "    def _load_dem(self, dem_path):\n",
    "        print(f\"Loading DEM data from {dem_path}\", flush=True)\n",
    "        dem_flat = np.fromfile(dem_path, dtype='>4')\n",
    "        dem_data = dem_flat.reshape((8102, 8102))\n",
    "        print(f\"DEM data shape: {dem_data.shape}\", flush=True)\n",
    "        return dem_data\n",
    "    \n",
    "    def _load_baselines(self, baselines_path):\n",
    "        print(f\"Loading baselines data from {baselines_path}\", flush=True)\n",
    "        df = pd.read_csv(baselines_path, delim_whitespace=True, header=None, usecols=[2])\n",
    "        print(f\"Baselines data shape: {df.shape}\", flush=True)\n",
    "        return df[2].values.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.times)\n",
    "\n",
    "    def generate_random_noise(self):\n",
    "        return np.random.normal(loc=0.0, scale=self.random_noise_std, size=self.size)\n",
    "\n",
    "    def generate_tropospheric_noise(self):\n",
    "        noise = np.fft.fft2(np.random.randn(*self.size))\n",
    "        ky = np.fft.fftfreq(self.size[0])\n",
    "        kx = np.fft.fftfreq(self.size[1])\n",
    "        kx, ky = np.meshgrid(kx, ky)\n",
    "        k = np.sqrt(kx**2 + ky**2)\n",
    "        k[0, 0] = 1e-7\n",
    "        power = k ** (-self.tropospheric_noise_beta)\n",
    "        frac_noise = np.fft.ifft2(noise * power).real\n",
    "        std_val = frac_noise.std()\n",
    "        if std_val > 1e-9:\n",
    "            frac_noise = (frac_noise - frac_noise.mean()) / std_val\n",
    "        else:\n",
    "            frac_noise = frac_noise - frac_noise.mean()\n",
    "        return frac_noise * self.tropospheric_noise_scale\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_los_vector(incidence_angle_deg, satellite_azimuth_deg):\n",
    "        incidence_angle_rad = np.deg2rad(incidence_angle_deg)\n",
    "        satellite_azimuth_rad = np.deg2rad(satellite_azimuth_deg)\n",
    "        look_azimuth_rad = satellite_azimuth_rad + np.pi/2\n",
    "        l_east = np.sin(incidence_angle_rad) * np.sin(look_azimuth_rad)\n",
    "        l_north = np.sin(incidence_angle_rad) * np.cos(look_azimuth_rad)\n",
    "        l_up = np.cos(incidence_angle_rad)\n",
    "        return np.array([l_east, l_north, l_up])\n",
    "\n",
    "    def generate_subsidence(self, delta_P):\n",
    "        y, x = np.indices(self.size)\n",
    "        cx, cy = self.size[1] // 2, self.size[0] // 2\n",
    "        r_sq = (x - cx)**2 + (y - cy)**2\n",
    "        r = np.sqrt(r_sq)\n",
    "        factor = (-1 / np.pi) * self.cm * (1 - self.nu) * delta_P * self.V\n",
    "        denominator_base = r**2 + self.D**2\n",
    "        denominator_base[denominator_base < 1e-9] = 1e-9\n",
    "        uz = factor * (self.D / (denominator_base**1.5))\n",
    "        ur = factor * (r / (denominator_base**1.5))\n",
    "        azimuth = np.arctan2(y - cy, x - cx)\n",
    "        ux = ur * np.cos(azimuth)\n",
    "        uy = ur * np.sin(azimuth)\n",
    "        los_vector_calc = Noise2NoiseDataset.calculate_los_vector(self.incidence_angle_deg, self.satellite_azimuth_deg)\n",
    "        simulated_interferogram = (ux * los_vector_calc[0]) + \\\n",
    "                                  (uy * los_vector_calc[1]) + \\\n",
    "                                  (uz * los_vector_calc[2])\n",
    "        return simulated_interferogram\n",
    "\n",
    "    def get_times(self):\n",
    "        if self.total_days < 1 or self.interval_days <=0:\n",
    "             return np.array([1.0])\n",
    "        return np.arange(1, self.total_days + 1, self.interval_days)\n",
    "\n",
    "    def _get_clean_subsidence_image(self, t):\n",
    "        delta_P_final = -self.S_max * ((np.pi * self.D**2) / (self.cm * (1 - self.nu) * self.V))\n",
    "        current_time_factor = 0.0\n",
    "        if callable(self.f_t):\n",
    "            if len(self.times) > 0:\n",
    "                current_time_factor = self.f_t(t, self.times, self.total_time)\n",
    "            else:\n",
    "                current_time_factor = t / self.total_time if self.total_time > 0 else 0\n",
    "        else: \n",
    "            current_time_factor = t / self.total_time if self.total_time > 0 else 0\n",
    "        delta_P_current = -delta_P_final * current_time_factor\n",
    "        return self.generate_subsidence(delta_P=delta_P_current)\n",
    "\n",
    "    def _get_orbit_geometry(self):\n",
    "        if self.orbit_type == 'ascending': return 40, 15\n",
    "        elif self.orbit_type == 'descending': return 40, 195\n",
    "        else: raise ValueError(\"Invalid orbit type.\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_time = self.times[idx]\n",
    "        clean_image = self._get_clean_subsidence_image(current_time)\n",
    "        noise1_random = self.generate_random_noise()\n",
    "        noise1_tropo = self.generate_tropospheric_noise()\n",
    "        noisy_image1 = clean_image + noise1_random + noise1_tropo\n",
    "        noise2_random = self.generate_random_noise()\n",
    "        noise2_tropo = self.generate_tropospheric_noise()\n",
    "        noisy_image2 = clean_image + noise2_random + noise2_tropo\n",
    "        clean_image_tensor = torch.from_numpy(clean_image.copy()).float().unsqueeze(0)\n",
    "        noisy_image1_tensor = torch.from_numpy(noisy_image1.copy()).float().unsqueeze(0)\n",
    "        noisy_image2_tensor = torch.from_numpy(noisy_image2.copy()).float().unsqueeze(0)\n",
    "        return noisy_image1_tensor, noisy_image2_tensor, clean_image_tensor\n",
    "\n",
    "def f_linear(t, times_array, total_time_val):\n",
    "    if total_time_val == 0: return 0\n",
    "    return t / total_time_val\n",
    "\n",
    "def f_log(t, times_array, total_time_val):\n",
    "    if total_time_val <= 0: return 0\n",
    "    if t <= 0: t = 1e-6 \n",
    "    min_time_in_series = times_array[0] if len(times_array)>0 and times_array[0] > 0 else 1.0\n",
    "    adjusted_t = (t - min_time_in_series) + 1\n",
    "    adjusted_total_time = (total_time_val - min_time_in_series) + 1\n",
    "    if adjusted_total_time <= 1:\n",
    "        return 1.0 if t >= total_time_val else (t/total_time_val if total_time_val > 0 else 0)\n",
    "    val = np.log1p(max(0, adjusted_t-1)) / np.log1p(max(1e-7, adjusted_total_time-1))\n",
    "    return min(max(0, val), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3819c4f-1168-4c95-ac16-8d2c1b0b9388",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data generation. Files will be saved to: Data\n",
      "Generating data for config: lin_asc_16\n",
      "Saved sample 10...\n",
      "Saved sample 20...\n",
      "Saved sample 30...\n",
      "Finished generating for config: lin_asc_16. Total samples so far: 30\n",
      "Generating data for config: log_asc_16\n",
      "Saved sample 40...\n",
      "Saved sample 50...\n",
      "Saved sample 60...\n",
      "Finished generating for config: log_asc_16. Total samples so far: 60\n",
      "Generating data for config: lin_desc_16\n",
      "Saved sample 70...\n",
      "Saved sample 80...\n",
      "Saved sample 90...\n",
      "Finished generating for config: lin_desc_16. Total samples so far: 90\n",
      "Generating data for config: log_desc_16\n",
      "Saved sample 100...\n",
      "Saved sample 110...\n",
      "Saved sample 120...\n",
      "Finished generating for config: log_desc_16. Total samples so far: 120\n",
      "Generating data for config: lin_asc_49\n",
      "Saved sample 130...\n",
      "Saved sample 140...\n",
      "Saved sample 150...\n",
      "Finished generating for config: lin_asc_49. Total samples so far: 150\n",
      "Generating data for config: log_asc_49\n",
      "Saved sample 160...\n",
      "Saved sample 170...\n",
      "Saved sample 180...\n",
      "Finished generating for config: log_asc_49. Total samples so far: 180\n",
      "Generating data for config: lin_desc_49\n",
      "Saved sample 190...\n",
      "Saved sample 200...\n",
      "Saved sample 210...\n",
      "Finished generating for config: lin_desc_49. Total samples so far: 210\n",
      "Generating data for config: log_desc_49\n",
      "Saved sample 220...\n",
      "Saved sample 230...\n",
      "Saved sample 240...\n",
      "Finished generating for config: log_desc_49. Total samples so far: 240\n",
      "Data generation complete. Total samples: 240. Manifest saved to Data/manifest.csv\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (1500, 1500)\n",
    "S_MAX = 5.0\n",
    "D_DEPTH = 50\n",
    "NU = 0.25\n",
    "CM = 1.0\n",
    "V_PARAM = 1.0\n",
    "RANDOM_NOISE_STD = 0.56\n",
    "TROPOSPHERIC_NOISE_BETA = 1.82\n",
    "TROPOSPHERIC_NOISE_SCALE = 1.0\n",
    "TOTAL_DAYS = 1460\n",
    "INTERVAL_DAYS = 49\n",
    "\n",
    "# IMPORTANT: Change this to your Google Drive path if using Drive\n",
    "PRECOMPUTED_DATA_ROOT = r\"Data\"\n",
    "\n",
    "def generate_and_save_data():\n",
    "    print(f\"Starting data generation. Files will be saved to: {PRECOMPUTED_DATA_ROOT}\")\n",
    "    os.makedirs(os.path.join(PRECOMPUTED_DATA_ROOT, 'noisy1'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(PRECOMPUTED_DATA_ROOT, 'noisy2'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(PRECOMPUTED_DATA_ROOT, 'clean'), exist_ok=True)\n",
    "\n",
    "    manifest_data = []\n",
    "    global_sample_idx = 0\n",
    "\n",
    "    dataset_configs = [\n",
    "        {'name': 'lin_asc_16', 'f_t': -1, 'orbit': 'ascending', 'interval': 16},\n",
    "        {'name': 'log_asc_16', 'f_t': f_log, 'orbit': 'ascending', 'interval': 16},\n",
    "        {'name': 'lin_desc_16', 'f_t': -1, 'orbit': 'descending', 'interval': 16},\n",
    "        {'name': 'log_desc_16', 'f_t': f_log, 'orbit': 'descending', 'interval': 16},\n",
    "        {'name': 'lin_asc_49', 'f_t': -1, 'orbit': 'ascending', 'interval': 49},\n",
    "        {'name': 'log_asc_49', 'f_t': f_log, 'orbit': 'ascending', 'interval': 49},\n",
    "        {'name': 'lin_desc_49', 'f_t': -1, 'orbit': 'descending', 'interval': 49},\n",
    "        {'name': 'log_desc_49', 'f_t': f_log, 'orbit': 'descending', 'interval': 49}\n",
    "    ]\n",
    "\n",
    "    for config in dataset_configs:\n",
    "        print(f\"Generating data for config: {config['name']}\")\n",
    "        gen_dataset = Noise2NoiseDataset(\n",
    "            size=IMG_SIZE, S_max=S_MAX, D=D_DEPTH, nu=NU, cm=CM, V=V_PARAM,\n",
    "            random_noise_std=RANDOM_NOISE_STD, tropospheric_noise_beta=TROPOSPHERIC_NOISE_BETA,\n",
    "            tropospheric_noise_scale=TROPOSPHERIC_NOISE_SCALE, total_days=TOTAL_DAYS,\n",
    "            interval_days=INTERVAL_DAYS, f_t=config['f_t'], orbit_type=config['orbit']\n",
    "        )\n",
    "        \n",
    "        if len(gen_dataset) == 0:\n",
    "            print(f\"Warning: No samples generated for config {config['name']}. Check total_days and interval_days.\")\n",
    "            continue\n",
    "\n",
    "        for i in range(len(gen_dataset)):\n",
    "            try:\n",
    "                noisy1_tensor, noisy2_tensor, clean_tensor = gen_dataset[i]\n",
    "\n",
    "                noisy1_fname = os.path.join('noisy1', f'sample_{global_sample_idx:06d}_noisy1.pt')\n",
    "                noisy2_fname = os.path.join('noisy2', f'sample_{global_sample_idx:06d}_noisy2.pt')\n",
    "                clean_fname = os.path.join('clean', f'sample_{global_sample_idx:06d}_clean.pt')\n",
    "\n",
    "                torch.save(noisy1_tensor, os.path.join(PRECOMPUTED_DATA_ROOT, noisy1_fname))\n",
    "                torch.save(noisy2_tensor, os.path.join(PRECOMPUTED_DATA_ROOT, noisy2_fname))\n",
    "                torch.save(clean_tensor, os.path.join(PRECOMPUTED_DATA_ROOT, clean_fname))\n",
    "\n",
    "                manifest_data.append({\n",
    "                    'id': global_sample_idx,\n",
    "                    'config_name': config['name'],\n",
    "                    'original_idx_in_config': i,\n",
    "                    'time_step': gen_dataset.times[i],\n",
    "                    'noisy1_path': noisy1_fname,\n",
    "                    'noisy2_path': noisy2_fname,\n",
    "                    'clean_path': clean_fname\n",
    "                })\n",
    "                global_sample_idx += 1\n",
    "                if global_sample_idx % 10 == 0: # Print progress\n",
    "                    print(f\"Saved sample {global_sample_idx}...\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating/saving sample {global_sample_idx} (original index {i} in config {config['name']}): {e}\")\n",
    "                # Optionally, decide if you want to skip or halt on error\n",
    "                continue\n",
    "        print(f\"Finished generating for config: {config['name']}. Total samples so far: {global_sample_idx}\")\n",
    "\n",
    "\n",
    "    manifest_df = pd.DataFrame(manifest_data)\n",
    "    manifest_path = os.path.join(PRECOMPUTED_DATA_ROOT, 'manifest.csv')\n",
    "    manifest_df.to_csv(manifest_path, index=False)\n",
    "    print(f\"Data generation complete. Total samples: {global_sample_idx}. Manifest saved to {manifest_path}\")\n",
    "\n",
    "generate_and_save_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GDAL / PyTorch)",
   "language": "python",
   "name": "gdal-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
