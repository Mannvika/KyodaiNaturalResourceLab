{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a67c03-afbd-4eb0-a3fc-338f32adbf41",
   "metadata": {},
   "source": [
    "# 1. Generating InSAR Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7610f358-c488-4391-89e1-f8ad76a65788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac82bd6-47e4-4e3f-9352-42f936019bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Noise2NoiseDataset(Dataset):\n",
    "    def __init__(self, size, S_max=5.0, D=50, nu=0.25, cm=1.0, V=1.0,\n",
    "                 random_noise_std=0.56, tropospheric_noise_beta=1.82, tropospheric_noise_scale=1.0,\n",
    "                 total_days=1460, interval_days=49, f_t=-1, orbit_type='ascending', dem_path='dem.dehm_be', baselines_path='baselines.txt'):\n",
    "        self.size = size\n",
    "        self.S_max = S_max\n",
    "        self.D = D\n",
    "        self.nu = nu\n",
    "        self.cm = cm\n",
    "        self.V = V\n",
    "        self.random_noise_std = random_noise_std\n",
    "        self.tropospheric_noise_beta = tropospheric_noise_beta\n",
    "        self.tropospheric_noise_scale = tropospheric_noise_scale\n",
    "        self.total_days = total_days\n",
    "        self.interval_days = interval_days\n",
    "        self.f_t = f_t\n",
    "        self.orbit_type = orbit_type\n",
    "        self.baselines = self._load_baselines(baselines_path)\n",
    "\n",
    "        full_dem_data = self._load_dem(dem_path)\n",
    "\n",
    "        max_x = self.dem_data.shape[1] - self.size[1]\n",
    "        max_y = self.dem_data.shape[0] - self.size[0]\n",
    "        rand_x = np.random.randint(0, max_x)\n",
    "        rand_y = np.random.randint(0, max_y)\n",
    "        self.rem_patch = full_dem_data[rand_y:rand_y + self.size[0], \n",
    "                                rand_x:rand_x + self.size[1]]\n",
    "\n",
    "        self.incidence_angle_deg, self.satellite_azimuth_deg = self._get_orbit_geometry()\n",
    "        self.times = self.get_times()\n",
    "        \n",
    "        if len(self.times) == 0:\n",
    "            self.total_time = 1.0\n",
    "        elif len(self.times) == 1:\n",
    "             self.total_time = self.times[0] if self.times[0] > 0 else 1.0\n",
    "        else:\n",
    "            self.total_time = self.times[-1] if self.times[-1] > 0 else 1.0\n",
    "        if self.total_time <=0: self.total_time = 1.0\n",
    "\n",
    "    def _load_dem(self, dem_path):\n",
    "        data_type = np.dtype('>f4')\n",
    "        raw_data = np.fromfile(path, dtype=data_type)\n",
    "        dem_data = raw_data.reshape((8102, 8102))\n",
    "        return dem_data\n",
    "    \n",
    "    def _load_baselines(self, baselines_path):\n",
    "        print(f\"Loading baselines data from {baselines_path}\", flush=True)\n",
    "        df = pd.read_csv(baselines_path, delim_whitespace=True, header=None, usecols=[2])\n",
    "        print(f\"Baselines data shape: {df.shape}\", flush=True)\n",
    "        return df[2].values.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.times)\n",
    "\n",
    "    def generate_random_noise(self):\n",
    "        return np.random.normal(loc=0.0, scale=self.random_noise_std, size=self.size)\n",
    "\n",
    "    def generate_tropospheric_noise(self):\n",
    "        noise = np.fft.fft2(np.random.randn(*self.size))\n",
    "        ky = np.fft.fftfreq(self.size[0])\n",
    "        kx = np.fft.fftfreq(self.size[1])\n",
    "        kx, ky = np.meshgrid(kx, ky)\n",
    "        k = np.sqrt(kx**2 + ky**2)\n",
    "        k[0, 0] = 1e-7\n",
    "        power = k ** (-self.tropospheric_noise_beta)\n",
    "        frac_noise = np.fft.ifft2(noise * power).real\n",
    "        std_val = frac_noise.std()\n",
    "        if std_val > 1e-9:\n",
    "            frac_noise = (frac_noise - frac_noise.mean()) / std_val\n",
    "        else:\n",
    "            frac_noise = frac_noise - frac_noise.mean()\n",
    "        return frac_noise * self.tropospheric_noise_scale\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_los_vector(incidence_angle_deg, satellite_azimuth_deg):\n",
    "        incidence_angle_rad = np.deg2rad(incidence_angle_deg)\n",
    "        satellite_azimuth_rad = np.deg2rad(satellite_azimuth_deg)\n",
    "        look_azimuth_rad = satellite_azimuth_rad + np.pi/2\n",
    "        l_east = np.sin(incidence_angle_rad) * np.sin(look_azimuth_rad)\n",
    "        l_north = np.sin(incidence_angle_rad) * np.cos(look_azimuth_rad)\n",
    "        l_up = np.cos(incidence_angle_rad)\n",
    "        return np.array([l_east, l_north, l_up])\n",
    "\n",
    "    def generate_subsidence(self, delta_P):\n",
    "        y, x = np.indices(self.size)\n",
    "        cx, cy = self.size[1] // 2, self.size[0] // 2\n",
    "        r_sq = (x - cx)**2 + (y - cy)**2\n",
    "        r = np.sqrt(r_sq)\n",
    "        factor = (-1 / np.pi) * self.cm * (1 - self.nu) * delta_P * self.V\n",
    "        denominator_base = r**2 + self.D**2\n",
    "        denominator_base[denominator_base < 1e-9] = 1e-9\n",
    "        uz = factor * (self.D / (denominator_base**1.5))\n",
    "        ur = factor * (r / (denominator_base**1.5))\n",
    "        azimuth = np.arctan2(y - cy, x - cx)\n",
    "        ux = ur * np.cos(azimuth)\n",
    "        uy = ur * np.sin(azimuth)\n",
    "        los_vector_calc = Noise2NoiseDataset.calculate_los_vector(self.incidence_angle_deg, self.satellite_azimuth_deg)\n",
    "        simulated_interferogram = (ux * los_vector_calc[0]) + \\\n",
    "                                  (uy * los_vector_calc[1]) + \\\n",
    "                                  (uz * los_vector_calc[2])\n",
    "        return simulated_interferogram\n",
    "    \n",
    "    def generate_topographic_noise(self):\n",
    "        delta_h = self.dem_patch\n",
    "        b_perp = np.random.choice(self.baselines)\n",
    "        WAVELENGTH = 0.24\n",
    "        SLANT_RANGE = 850000\n",
    "        incidence_angle_rad = np.deg2rad(self.incidence_angle_deg)\n",
    "        numerator = -4 * np.pi * b_perp\n",
    "        denominator = WAVELENGTH * SLANT_RANGE * np.sin(incidence_angle_rad)\n",
    "        \n",
    "        if abs(denominator) < 1e-9:\n",
    "            return np.zeros(self.size)\n",
    "\n",
    "        topo_phase_noise = (numerator / denominator) * delta_h\n",
    "        return topo_phase_noise\n",
    "\n",
    "    def get_times(self):\n",
    "        if self.total_days < 1 or self.interval_days <=0:\n",
    "             return np.array([1.0])\n",
    "        return np.arange(1, self.total_days + 1, self.interval_days)\n",
    "\n",
    "    def _get_clean_subsidence_image(self, t):\n",
    "        delta_P_final = -self.S_max * ((np.pi * self.D**2) / (self.cm * (1 - self.nu) * self.V))\n",
    "        current_time_factor = 0.0\n",
    "        if callable(self.f_t):\n",
    "            if len(self.times) > 0:\n",
    "                current_time_factor = self.f_t(t, self.times, self.total_time)\n",
    "            else:\n",
    "                current_time_factor = t / self.total_time if self.total_time > 0 else 0\n",
    "        else: \n",
    "            current_time_factor = t / self.total_time if self.total_time > 0 else 0\n",
    "        delta_P_current = -delta_P_final * current_time_factor\n",
    "        return self.generate_subsidence(delta_P=delta_P_current)\n",
    "\n",
    "    def _get_orbit_geometry(self):\n",
    "        if self.orbit_type == 'ascending': return 40, 15\n",
    "        elif self.orbit_type == 'descending': return 40, 195\n",
    "        else: raise ValueError(\"Invalid orbit type.\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_time = self.times[idx]\n",
    "        clean_image = self._get_clean_subsidence_image(current_time)\n",
    "        noise1_random = self.generate_random_noise()\n",
    "        noise1_tropo = self.generate_tropospheric_noise()\n",
    "        noise1_topo = self.generate_topographic_noise()\n",
    "        noisy_image1 = clean_image + noise1_random + noise1_tropo + noise1_topo\n",
    "        noise2_random = self.generate_random_noise()\n",
    "        noise2_tropo = self.generate_tropospheric_noise()\n",
    "        noise2_topo = self.generate_topographic_noise()\n",
    "        noisy_image2 = clean_image + noise2_random + noise2_tropo + noise2_topo\n",
    "        clean_image_tensor = torch.from_numpy(clean_image.copy()).float().unsqueeze(0)\n",
    "        noisy_image1_tensor = torch.from_numpy(noisy_image1.copy()).float().unsqueeze(0)\n",
    "        noisy_image2_tensor = torch.from_numpy(noisy_image2.copy()).float().unsqueeze(0)\n",
    "        return noisy_image1_tensor, noisy_image2_tensor, clean_image_tensor\n",
    "\n",
    "def f_linear(t, times_array, total_time_val):\n",
    "    if total_time_val == 0: return 0\n",
    "    return t / total_time_val\n",
    "\n",
    "def f_log(t, times_array, total_time_val):\n",
    "    if total_time_val <= 0: return 0\n",
    "    if t <= 0: t = 1e-6 \n",
    "    min_time_in_series = times_array[0] if len(times_array)>0 and times_array[0] > 0 else 1.0\n",
    "    adjusted_t = (t - min_time_in_series) + 1\n",
    "    adjusted_total_time = (total_time_val - min_time_in_series) + 1\n",
    "    if adjusted_total_time <= 1:\n",
    "        return 1.0 if t >= total_time_val else (t/total_time_val if total_time_val > 0 else 0)\n",
    "    val = np.log1p(max(0, adjusted_t-1)) / np.log1p(max(1e-7, adjusted_total_time-1))\n",
    "    return min(max(0, val), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3819c4f-1168-4c95-ac16-8d2c1b0b9388",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data generation. Files will be saved to: Data2\n",
      "Generating data for config: lin_asc_49\n",
      "Loading baselines data from baselines.txt\n",
      "Baselines data shape: (403, 1)\n",
      "Loading DEM data from dem.dehm_be\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manav\\AppData\\Local\\Temp\\ipykernel_22204\\2920410172.py:49: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(baselines_path, delim_whitespace=True, header=None, usecols=[2])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "data type '>' not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m     manifest_df\u001b[38;5;241m.\u001b[39mto_csv(manifest_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData generation complete. Total samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mglobal_sample_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Manifest saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmanifest_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 79\u001b[0m \u001b[43mgenerate_and_save_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 31\u001b[0m, in \u001b[0;36mgenerate_and_save_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m config \u001b[38;5;129;01min\u001b[39;00m dataset_configs:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating data for config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m     gen_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mNoise2NoiseDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mS_MAX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mD_DEPTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mV_PARAM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_noise_std\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRANDOM_NOISE_STD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtropospheric_noise_beta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTROPOSPHERIC_NOISE_BETA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtropospheric_noise_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTROPOSPHERIC_NOISE_SCALE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTOTAL_DAYS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterval_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINTERVAL_DAYS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf_t\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morbit_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43morbit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(gen_dataset) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: No samples generated for config \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Check total_days and interval_days.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 20\u001b[0m, in \u001b[0;36mNoise2NoiseDataset.__init__\u001b[1;34m(self, size, S_max, D, nu, cm, V, random_noise_std, tropospheric_noise_beta, tropospheric_noise_scale, total_days, interval_days, f_t, orbit_type, dem_path, baselines_path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morbit_type \u001b[38;5;241m=\u001b[39m orbit_type\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbaselines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_baselines(baselines_path)\n\u001b[1;32m---> 20\u001b[0m full_dem_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_dem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdem_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m max_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdem_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     23\u001b[0m max_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdem_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[3], line 42\u001b[0m, in \u001b[0;36mNoise2NoiseDataset._load_dem\u001b[1;34m(self, dem_path)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_dem\u001b[39m(\u001b[38;5;28mself\u001b[39m, dem_path):\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading DEM data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdem_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 42\u001b[0m     dem_flat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdem_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m>4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     dem_data \u001b[38;5;241m=\u001b[39m dem_flat\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m8102\u001b[39m, \u001b[38;5;241m8102\u001b[39m))\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEM data shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdem_data\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: data type '>' not understood"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (1500, 1500)\n",
    "S_MAX = 5.0\n",
    "D_DEPTH = 50\n",
    "NU = 0.25\n",
    "CM = 1.0\n",
    "V_PARAM = 1.0\n",
    "RANDOM_NOISE_STD = 0.56\n",
    "TROPOSPHERIC_NOISE_BETA = 1.82\n",
    "TROPOSPHERIC_NOISE_SCALE = 1.0\n",
    "TOTAL_DAYS = 1460\n",
    "INTERVAL_DAYS = 49\n",
    "\n",
    "# IMPORTANT: Change this to your Google Drive path if using Drive\n",
    "PRECOMPUTED_DATA_ROOT = r\"Data2\"\n",
    "\n",
    "def generate_and_save_data():\n",
    "    print(f\"Starting data generation. Files will be saved to: {PRECOMPUTED_DATA_ROOT}\")\n",
    "    os.makedirs(os.path.join(PRECOMPUTED_DATA_ROOT, 'noisy1'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(PRECOMPUTED_DATA_ROOT, 'noisy2'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(PRECOMPUTED_DATA_ROOT, 'clean'), exist_ok=True)\n",
    "\n",
    "    manifest_data = []\n",
    "    global_sample_idx = 0\n",
    "\n",
    "    dataset_configs = [\n",
    "        {'name': 'lin_asc_49', 'f_t': -1, 'orbit': 'ascending', 'interval': 49},\n",
    "    ]\n",
    "\n",
    "    for config in dataset_configs:\n",
    "        print(f\"Generating data for config: {config['name']}\")\n",
    "        gen_dataset = Noise2NoiseDataset(\n",
    "            size=IMG_SIZE, S_max=S_MAX, D=D_DEPTH, nu=NU, cm=CM, V=V_PARAM,\n",
    "            random_noise_std=RANDOM_NOISE_STD, tropospheric_noise_beta=TROPOSPHERIC_NOISE_BETA,\n",
    "            tropospheric_noise_scale=TROPOSPHERIC_NOISE_SCALE, total_days=TOTAL_DAYS,\n",
    "            interval_days=INTERVAL_DAYS, f_t=config['f_t'], orbit_type=config['orbit']\n",
    "        )\n",
    "        \n",
    "        if len(gen_dataset) == 0:\n",
    "            print(f\"Warning: No samples generated for config {config['name']}. Check total_days and interval_days.\")\n",
    "            continue\n",
    "\n",
    "        for i in range(len(gen_dataset)):\n",
    "            try:\n",
    "                noisy1_tensor, noisy2_tensor, clean_tensor = gen_dataset[i]\n",
    "\n",
    "                noisy1_fname = os.path.join('noisy1', f'sample_{global_sample_idx:06d}_noisy1.pt')\n",
    "                noisy2_fname = os.path.join('noisy2', f'sample_{global_sample_idx:06d}_noisy2.pt')\n",
    "                clean_fname = os.path.join('clean', f'sample_{global_sample_idx:06d}_clean.pt')\n",
    "\n",
    "                torch.save(noisy1_tensor, os.path.join(PRECOMPUTED_DATA_ROOT, noisy1_fname))\n",
    "                torch.save(noisy2_tensor, os.path.join(PRECOMPUTED_DATA_ROOT, noisy2_fname))\n",
    "                torch.save(clean_tensor, os.path.join(PRECOMPUTED_DATA_ROOT, clean_fname))\n",
    "\n",
    "                manifest_data.append({\n",
    "                    'id': global_sample_idx,\n",
    "                    'config_name': config['name'],\n",
    "                    'original_idx_in_config': i,\n",
    "                    'time_step': gen_dataset.times[i],\n",
    "                    'noisy1_path': noisy1_fname,\n",
    "                    'noisy2_path': noisy2_fname,\n",
    "                    'clean_path': clean_fname\n",
    "                })\n",
    "                global_sample_idx += 1\n",
    "                if global_sample_idx % 10 == 0: # Print progress\n",
    "                    print(f\"Saved sample {global_sample_idx}...\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating/saving sample {global_sample_idx} (original index {i} in config {config['name']}): {e}\")\n",
    "                # Optionally, decide if you want to skip or halt on error\n",
    "                continue\n",
    "        print(f\"Finished generating for config: {config['name']}. Total samples so far: {global_sample_idx}\")\n",
    "\n",
    "\n",
    "    manifest_df = pd.DataFrame(manifest_data)\n",
    "    manifest_path = os.path.join(PRECOMPUTED_DATA_ROOT, 'manifest.csv')\n",
    "    manifest_df.to_csv(manifest_path, index=False)\n",
    "    print(f\"Data generation complete. Total samples: {global_sample_idx}. Manifest saved to {manifest_path}\")\n",
    "\n",
    "generate_and_save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8869848f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KyotoUniverstyResearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
