{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64da22c5-9823-40ff-a3a3-38ece68bdeef",
   "metadata": {},
   "source": [
    "# 1. Developing and Saving the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ab1061f-420d-43c4-943a-ac3bcdbd06ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b5bcf3-0367-4766-858c-5368d6951340",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Noise2NoiseDataset(Dataset):\n",
    "    def __init__(self, size, S_max=5.0, D=50, nu=0.25, cm=1.0, V=1.0,\n",
    "                 random_noise_std=0.56, tropospheric_noise_beta=1.82, tropospheric_noise_scale=1.0,\n",
    "                 total_days=1460, interval_days=49, f_t=-1, orbit_type='ascending'):\n",
    "        self.size = size\n",
    "        self.S_max = S_max\n",
    "        self.D = D\n",
    "        self.nu = nu\n",
    "        self.cm = cm\n",
    "        self.V = V\n",
    "        self.random_noise_std = random_noise_std\n",
    "        self.tropospheric_noise_beta = tropospheric_noise_beta\n",
    "        self.tropospheric_noise_scale = tropospheric_noise_scale\n",
    "        self.total_days = total_days\n",
    "        self.interval_days = interval_days\n",
    "        self.f_t = f_t\n",
    "        self.orbit_type = orbit_type\n",
    "\n",
    "        self.incidence_angle_deg, self.satellite_azimuth_deg = self._get_orbit_geometry()\n",
    "        self.times = self.get_times()\n",
    "        \n",
    "        if len(self.times) == 0:\n",
    "            self.total_time = 1.0\n",
    "        elif len(self.times) == 1:\n",
    "             self.total_time = self.times[0] if self.times[0] > 0 else 1.0\n",
    "        else:\n",
    "            self.total_time = self.times[-1] if self.times[-1] > 0 else 1.0\n",
    "        if self.total_time <=0: self.total_time = 1.0\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.times)\n",
    "\n",
    "    def generate_random_noise(self):\n",
    "        return np.random.normal(loc=0.0, scale=self.random_noise_std, size=self.size)\n",
    "\n",
    "    def generate_tropospheric_noise(self):\n",
    "        noise = np.fft.fft2(np.random.randn(*self.size))\n",
    "        ky = np.fft.fftfreq(self.size[0])\n",
    "        kx = np.fft.fftfreq(self.size[1])\n",
    "        kx, ky = np.meshgrid(kx, ky)\n",
    "        k = np.sqrt(kx**2 + ky**2)\n",
    "        k[0, 0] = 1e-7\n",
    "        power = k ** (-self.tropospheric_noise_beta)\n",
    "        frac_noise = np.fft.ifft2(noise * power).real\n",
    "        std_val = frac_noise.std()\n",
    "        if std_val > 1e-9:\n",
    "            frac_noise = (frac_noise - frac_noise.mean()) / std_val\n",
    "        else:\n",
    "            frac_noise = frac_noise - frac_noise.mean()\n",
    "        return frac_noise * self.tropospheric_noise_scale\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_los_vector(incidence_angle_deg, satellite_azimuth_deg):\n",
    "        incidence_angle_rad = np.deg2rad(incidence_angle_deg)\n",
    "        satellite_azimuth_rad = np.deg2rad(satellite_azimuth_deg)\n",
    "        look_azimuth_rad = satellite_azimuth_rad + np.pi/2\n",
    "        l_east = np.sin(incidence_angle_rad) * np.sin(look_azimuth_rad)\n",
    "        l_north = np.sin(incidence_angle_rad) * np.cos(look_azimuth_rad)\n",
    "        l_up = np.cos(incidence_angle_rad)\n",
    "        return np.array([l_east, l_north, l_up])\n",
    "\n",
    "    def generate_subsidence(self, delta_P):\n",
    "        y, x = np.indices(self.size)\n",
    "        cx, cy = self.size[1] // 2, self.size[0] // 2\n",
    "        r_sq = (x - cx)**2 + (y - cy)**2\n",
    "        r = np.sqrt(r_sq)\n",
    "        factor = (-1 / np.pi) * self.cm * (1 - self.nu) * delta_P * self.V\n",
    "        denominator_base = r**2 + self.D**2\n",
    "        denominator_base[denominator_base < 1e-9] = 1e-9\n",
    "        uz = factor * (self.D / (denominator_base**1.5))\n",
    "        ur = factor * (r / (denominator_base**1.5))\n",
    "        azimuth = np.arctan2(y - cy, x - cx)\n",
    "        ux = ur * np.cos(azimuth)\n",
    "        uy = ur * np.sin(azimuth)\n",
    "        los_vector_calc = Noise2NoiseDataset.calculate_los_vector(self.incidence_angle_deg, self.satellite_azimuth_deg)\n",
    "        simulated_interferogram = (ux * los_vector_calc[0]) + \\\n",
    "                                  (uy * los_vector_calc[1]) + \\\n",
    "                                  (uz * los_vector_calc[2])\n",
    "        return simulated_interferogram\n",
    "\n",
    "    def get_times(self):\n",
    "        if self.total_days < 1 or self.interval_days <=0:\n",
    "             return np.array([1.0])\n",
    "        return np.arange(1, self.total_days + 1, self.interval_days)\n",
    "\n",
    "    def _get_clean_subsidence_image(self, t):\n",
    "        delta_P_final = -self.S_max * ((np.pi * self.D**2) / (self.cm * (1 - self.nu) * self.V))\n",
    "        current_time_factor = 0.0\n",
    "        if callable(self.f_t):\n",
    "            if len(self.times) > 0:\n",
    "                current_time_factor = self.f_t(t, self.times, self.total_time)\n",
    "            else:\n",
    "                current_time_factor = t / self.total_time if self.total_time > 0 else 0\n",
    "        else: \n",
    "            current_time_factor = t / self.total_time if self.total_time > 0 else 0\n",
    "        delta_P_current = -delta_P_final * current_time_factor\n",
    "        return self.generate_subsidence(delta_P=delta_P_current)\n",
    "\n",
    "    def _get_orbit_geometry(self):\n",
    "        if self.orbit_type == 'ascending': return 40, 15\n",
    "        elif self.orbit_type == 'descending': return 40, 195\n",
    "        else: raise ValueError(\"Invalid orbit type.\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_time = self.times[idx]\n",
    "        clean_image = self._get_clean_subsidence_image(current_time)\n",
    "        noise1_random = self.generate_random_noise()\n",
    "        noise1_tropo = self.generate_tropospheric_noise()\n",
    "        noisy_image1 = clean_image + noise1_random + noise1_tropo\n",
    "        noise2_random = self.generate_random_noise()\n",
    "        noise2_tropo = self.generate_tropospheric_noise()\n",
    "        noisy_image2 = clean_image + noise2_random + noise2_tropo\n",
    "        clean_image_tensor = torch.from_numpy(clean_image.copy()).float().unsqueeze(0)\n",
    "        noisy_image1_tensor = torch.from_numpy(noisy_image1.copy()).float().unsqueeze(0)\n",
    "        noisy_image2_tensor = torch.from_numpy(noisy_image2.copy()).float().unsqueeze(0)\n",
    "        return noisy_image1_tensor, noisy_image2_tensor, clean_image_tensor\n",
    "\n",
    "# --- Time Evolution Functions ---\n",
    "def f_linear(t, times_array, total_time_val):\n",
    "    if total_time_val == 0: return 0\n",
    "    return t / total_time_val\n",
    "\n",
    "def f_log(t, times_array, total_time_val):\n",
    "    if total_time_val <= 0: return 0\n",
    "    if t <= 0: t = 1e-6 \n",
    "    min_time_in_series = times_array[0] if len(times_array)>0 and times_array[0] > 0 else 1.0\n",
    "    adjusted_t = (t - min_time_in_series) + 1\n",
    "    adjusted_total_time = (total_time_val - min_time_in_series) + 1\n",
    "    if adjusted_total_time <= 1:\n",
    "        return 1.0 if t >= total_time_val else (t/total_time_val if total_time_val > 0 else 0)\n",
    "    val = np.log1p(max(0, adjusted_t-1)) / np.log1p(max(1e-7, adjusted_total_time-1))\n",
    "    return min(max(0, val), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f72e2632-b73e-4004-a69e-eeccefe6ca5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data generation. Files will be saved to: C:\\Users\\manav\\KyodaiNaturalResourceLab\\dataset\n",
      "Generating data for config: lin_asc\n",
      "Saved sample 10...\n",
      "Saved sample 20...\n",
      "Saved sample 30...\n",
      "Finished generating for config: lin_asc. Total samples so far: 30\n",
      "Generating data for config: log_asc\n",
      "Saved sample 40...\n",
      "Saved sample 50...\n",
      "Saved sample 60...\n",
      "Finished generating for config: log_asc. Total samples so far: 60\n",
      "Generating data for config: lin_desc\n",
      "Saved sample 70...\n",
      "Saved sample 80...\n",
      "Saved sample 90...\n",
      "Finished generating for config: lin_desc. Total samples so far: 90\n",
      "Generating data for config: log_desc\n",
      "Saved sample 100...\n",
      "Saved sample 110...\n",
      "Saved sample 120...\n",
      "Finished generating for config: log_desc. Total samples so far: 120\n",
      "Data generation complete. Total samples: 120. Manifest saved to C:\\Users\\manav\\KyodaiNaturalResourceLab\\dataset\\manifest.csv\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (1500, 1500) # Large image size\n",
    "S_MAX = 5.0\n",
    "D_DEPTH = 50\n",
    "NU = 0.25\n",
    "CM = 1.0\n",
    "V_PARAM = 1.0\n",
    "RANDOM_NOISE_STD = 0.56\n",
    "TROPOSPHERIC_NOISE_BETA = 1.82\n",
    "TROPOSPHERIC_NOISE_SCALE = 1.0\n",
    "TOTAL_DAYS = 1460\n",
    "INTERVAL_DAYS = 49\n",
    "\n",
    "# --- Root directory for saving precomputed dataset ---\n",
    "# IMPORTANT: Change this to your Google Drive path if using Drive\n",
    "PRECOMPUTED_DATA_ROOT = r\"C:\\Users\\manav\\KyodaiNaturalResourceLab\\dataset\"\n",
    "# ==============================================================\n",
    "# PHASE 1: DATA GENERATION AND SAVING (Run this section ONCE)\n",
    "# ==============================================================\n",
    "def generate_and_save_data():\n",
    "    print(f\"Starting data generation. Files will be saved to: {PRECOMPUTED_DATA_ROOT}\")\n",
    "    os.makedirs(os.path.join(PRECOMPUTED_DATA_ROOT, 'noisy1'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(PRECOMPUTED_DATA_ROOT, 'noisy2'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(PRECOMPUTED_DATA_ROOT, 'clean'), exist_ok=True)\n",
    "\n",
    "    manifest_data = []\n",
    "    global_sample_idx = 0\n",
    "\n",
    "    dataset_configs = [\n",
    "        {'name': 'lin_asc', 'f_t': -1, 'orbit': 'ascending'},\n",
    "        {'name': 'log_asc', 'f_t': f_log, 'orbit': 'ascending'},\n",
    "        {'name': 'lin_desc', 'f_t': -1, 'orbit': 'descending'},\n",
    "        {'name': 'log_desc', 'f_t': f_log, 'orbit': 'descending'}\n",
    "    ]\n",
    "\n",
    "    for config in dataset_configs:\n",
    "        print(f\"Generating data for config: {config['name']}\")\n",
    "        # Instantiate the original dataset for generation\n",
    "        gen_dataset = Noise2NoiseDataset(\n",
    "            size=IMG_SIZE, S_max=S_MAX, D=D_DEPTH, nu=NU, cm=CM, V=V_PARAM,\n",
    "            random_noise_std=RANDOM_NOISE_STD, tropospheric_noise_beta=TROPOSPHERIC_NOISE_BETA,\n",
    "            tropospheric_noise_scale=TROPOSPHERIC_NOISE_SCALE, total_days=TOTAL_DAYS,\n",
    "            interval_days=INTERVAL_DAYS, f_t=config['f_t'], orbit_type=config['orbit']\n",
    "        )\n",
    "        \n",
    "        if len(gen_dataset) == 0:\n",
    "            print(f\"Warning: No samples generated for config {config['name']}. Check total_days and interval_days.\")\n",
    "            continue\n",
    "\n",
    "        for i in range(len(gen_dataset)):\n",
    "            try:\n",
    "                noisy1_tensor, noisy2_tensor, clean_tensor = gen_dataset[i]\n",
    "\n",
    "                # Define file paths (relative to PRECOMPUTED_DATA_ROOT)\n",
    "                noisy1_fname = os.path.join('noisy1', f'sample_{global_sample_idx:06d}_noisy1.pt')\n",
    "                noisy2_fname = os.path.join('noisy2', f'sample_{global_sample_idx:06d}_noisy2.pt')\n",
    "                clean_fname = os.path.join('clean', f'sample_{global_sample_idx:06d}_clean.pt')\n",
    "\n",
    "                # Save tensors\n",
    "                torch.save(noisy1_tensor, os.path.join(PRECOMPUTED_DATA_ROOT, noisy1_fname))\n",
    "                torch.save(noisy2_tensor, os.path.join(PRECOMPUTED_DATA_ROOT, noisy2_fname))\n",
    "                torch.save(clean_tensor, os.path.join(PRECOMPUTED_DATA_ROOT, clean_fname))\n",
    "\n",
    "                manifest_data.append({\n",
    "                    'id': global_sample_idx,\n",
    "                    'config_name': config['name'],\n",
    "                    'original_idx_in_config': i,\n",
    "                    'time_step': gen_dataset.times[i],\n",
    "                    'noisy1_path': noisy1_fname,\n",
    "                    'noisy2_path': noisy2_fname,\n",
    "                    'clean_path': clean_fname\n",
    "                })\n",
    "                global_sample_idx += 1\n",
    "                if global_sample_idx % 10 == 0: # Print progress\n",
    "                    print(f\"Saved sample {global_sample_idx}...\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating/saving sample {global_sample_idx} (original index {i} in config {config['name']}): {e}\")\n",
    "                # Optionally, decide if you want to skip or halt on error\n",
    "                continue\n",
    "        print(f\"Finished generating for config: {config['name']}. Total samples so far: {global_sample_idx}\")\n",
    "\n",
    "\n",
    "    manifest_df = pd.DataFrame(manifest_data)\n",
    "    manifest_path = os.path.join(PRECOMPUTED_DATA_ROOT, 'manifest.csv')\n",
    "    manifest_df.to_csv(manifest_path, index=False)\n",
    "    print(f\"Data generation complete. Total samples: {global_sample_idx}. Manifest saved to {manifest_path}\")\n",
    "\n",
    "generate_and_save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7373325f-281c-46bb-a608-a93baf68850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrecomputedNoise2NoiseDataset(Dataset):\n",
    "    def __init__(self, manifest_file, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        try:\n",
    "            self.manifest = pd.read_csv(manifest_file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Manifest file not found at {manifest_file}\")\n",
    "            print(\"Please ensure you have run the data generation phase first.\")\n",
    "            self.manifest = pd.DataFrame() # Empty dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.manifest)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.manifest):\n",
    "            raise IndexError(\"Index out of bounds\")\n",
    "            \n",
    "        record = self.manifest.iloc[idx]\n",
    "        \n",
    "        noisy1_path = os.path.join(self.root_dir, record['noisy1_path'])\n",
    "        noisy2_path = os.path.join(self.root_dir, record['noisy2_path'])\n",
    "        clean_path = os.path.join(self.root_dir, record['clean_path'])\n",
    "\n",
    "        try:\n",
    "            noisy1_tensor = torch.load(noisy1_path)\n",
    "            noisy2_tensor = torch.load(noisy2_path)\n",
    "            clean_tensor = torch.load(clean_path)\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error loading file for sample id {record['id']}: {e}\")\n",
    "            # Return dummy data or raise error\n",
    "            dummy_tensor = torch.zeros((1, IMG_SIZE[0], IMG_SIZE[1]), dtype=torch.float)\n",
    "            return dummy_tensor, dummy_tensor, dummy_tensor\n",
    "        except Exception as e:\n",
    "            print(f\"Generic error loading file for sample id {record['id']}: {e}\")\n",
    "            dummy_tensor = torch.zeros((1, IMG_SIZE[0], IMG_SIZE[1]), dtype=torch.float)\n",
    "            return dummy_tensor, dummy_tensor, dummy_tensor\n",
    "\n",
    "\n",
    "        return noisy1_tensor, noisy2_tensor, clean_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9be1623-a6ca-4b9d-9aca-6f3c07f7d4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total precomputed samples: 120\n",
      "Train samples: 84\n",
      "Validation samples: 18\n",
      "Test samples: 18\n"
     ]
    }
   ],
   "source": [
    "# --- Load manifest and create datasets/dataloaders for training ---\n",
    "manifest_path = os.path.join(PRECOMPUTED_DATA_ROOT, 'manifest.csv')\n",
    "\n",
    "# Check if manifest exists before proceeding\n",
    "if not os.path.exists(manifest_path):\n",
    "    print(f\"Manifest file {manifest_path} not found. Please run the data generation phase first.\")\n",
    "    # You might want to exit or prevent further execution if manifest is missing\n",
    "    # For now, this will lead to an empty dataset if PrecomputedNoise2NoiseDataset handles it.\n",
    "    \n",
    "full_dataset = PrecomputedNoise2NoiseDataset(manifest_file=manifest_path, root_dir=PRECOMPUTED_DATA_ROOT)\n",
    "\n",
    "train_loader, val_loader, test_loader = None, None, None\n",
    "\n",
    "if len(full_dataset) > 0:\n",
    "    total_samples = len(full_dataset)\n",
    "    indices = list(range(total_samples))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    # test_ratio = 0.15 implicitly\n",
    "\n",
    "    if total_samples < 3:\n",
    "        train_indices = indices\n",
    "        val_indices, test_indices = [],[]\n",
    "    else:\n",
    "        train_split_idx = int(train_ratio * total_samples)\n",
    "        val_split_idx = train_split_idx + int(val_ratio * total_samples)\n",
    "        \n",
    "        train_indices = indices[:train_split_idx]\n",
    "        val_indices = indices[train_split_idx:val_split_idx]\n",
    "        test_indices = indices[val_split_idx:]\n",
    "\n",
    "        # Ensure all sets have at least one sample if total_samples allows\n",
    "        if not test_indices and val_indices: test_indices = val_indices[-1:]; val_indices = val_indices[:-1]\n",
    "        if not val_indices and train_indices: val_indices = train_indices[-1:]; train_indices = train_indices[:-1]\n",
    "\n",
    "\n",
    "    train_subset = Subset(full_dataset, train_indices)\n",
    "    val_subset = Subset(full_dataset, val_indices)\n",
    "    test_subset = Subset(full_dataset, test_indices)\n",
    "\n",
    "    print(f\"Total precomputed samples: {total_samples}\")\n",
    "    print(f\"Train samples: {len(train_subset)}\")\n",
    "    print(f\"Validation samples: {len(val_subset)}\")\n",
    "    print(f\"Test samples: {len(test_subset)}\")\n",
    "    \n",
    "    BATCH_SIZE = 1 # Keep batch size small for 1500x1500 images\n",
    "    if len(train_subset) > 0:\n",
    "        train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    if len(val_subset) > 0:\n",
    "        val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    if len(test_subset) > 0:\n",
    "        test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "else:\n",
    "    print(\"Full dataset is empty. Cannot create data loaders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c908cc6-cf3f-4dcd-bbda-6ed22045855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CNN Model (Simple U-Net like structure) ---\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=[32, 64, 128]): # Reduced features\n",
    "        super(SimpleUNet, self).__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        for feature in features:\n",
    "            self.downs.append(self._double_conv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "        self.bottleneck = self._double_conv(features[-1], features[-1] * 2)\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2))\n",
    "            self.ups.append(self._double_conv(feature * 2, feature))\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def _double_conv(self, in_c, out_c):\n",
    "        conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n",
    "        )\n",
    "        return conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        for down_conv in self.downs:\n",
    "            x = down_conv(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        for i in range(0, len(self.ups), 2):\n",
    "            x = self.ups[i](x)\n",
    "            skip_connection = skip_connections[i//2]\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = torch.nn.functional.interpolate(x, size=skip_connection.shape[2:])\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[i+1](concat_skip)\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cb17e92-f55c-453d-8b72-1641b5f5260c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manav\\AppData\\Local\\Temp\\ipykernel_5084\\2557251388.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE.type == 'cuda')) # Mixed precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "--- Epoch 1/5 ---\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 10860, 13004) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\KyotoUniverstyResearch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1243\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1243\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KyotoUniverstyResearch\\lib\\queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_empty\u001b[38;5;241m.\u001b[39mwait(remaining)\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 64\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_EPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 64\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m     66\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(loader, model, optimizer, criterion, device, scaler)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining loader is None, skipping training epoch.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (noisy1, noisy2, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[0;32m     24\u001b[0m     noisy1, noisy2 \u001b[38;5;241m=\u001b[39m noisy1\u001b[38;5;241m.\u001b[39mto(device), noisy2\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39m(device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KyotoUniverstyResearch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KyotoUniverstyResearch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1448\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1448\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1451\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KyotoUniverstyResearch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1402\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m   1401\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m-> 1402\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1403\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1404\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KyotoUniverstyResearch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1256\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1255\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1257\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1258\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 10860, 13004) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# --- Training Setup ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "MODEL_FEATURES = [16, 32, 64] # Further reduced features for 1500x1500\n",
    "model = SimpleUNet(in_channels=1, out_channels=1, features=MODEL_FEATURES).to(DEVICE)\n",
    "\n",
    "LEARNING_RATE = 1e-4 \n",
    "NUM_EPOCHS = 5 # Start with fewer epochs\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE.type == 'cuda')) # Mixed precision\n",
    "\n",
    "# --- Training and Validation Loops (mostly unchanged) ---\n",
    "def train_one_epoch(loader, model, optimizer, criterion, device, scaler):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    if loader is None:\n",
    "        print(\"Training loader is None, skipping training epoch.\")\n",
    "        return 0.0\n",
    "    for batch_idx, (noisy1, noisy2, _) in enumerate(loader):\n",
    "        noisy1, noisy2 = noisy1.to(device), noisy2.to(device)\n",
    "        with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):\n",
    "            denoised_output = model(noisy1)\n",
    "            loss = criterion(denoised_output, noisy2)\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        epoch_loss += loss.item()\n",
    "        if batch_idx % 10 == 0: print(f\"Train Batch {batch_idx}/{len(loader)}, Loss: {loss.item():.4f}\")\n",
    "    if len(loader) == 0: return 0.0\n",
    "    avg_epoch_loss = epoch_loss / len(loader)\n",
    "    print(f\"End of Epoch, Avg Training Loss: {avg_epoch_loss:.4f}\")\n",
    "    return avg_epoch_loss\n",
    "\n",
    "def validate_one_epoch(loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    if loader is None:\n",
    "        print(\"Validation loader is None, skipping validation epoch.\")\n",
    "        return float('inf')\n",
    "    with torch.no_grad():\n",
    "        for noisy1, noisy2, _ in loader:\n",
    "            noisy1, noisy2 = noisy1.to(device), noisy2.to(device)\n",
    "            with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):\n",
    "                denoised_output = model(noisy1)\n",
    "                loss = criterion(denoised_output, noisy2)\n",
    "            epoch_loss += loss.item()\n",
    "    if len(loader) == 0: return float('inf')\n",
    "    avg_epoch_loss = epoch_loss / len(loader)\n",
    "    print(f\"Validation Avg Loss: {avg_epoch_loss:.4f}\")\n",
    "    return avg_epoch_loss\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "train_losses, val_losses = [], []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "if train_loader is not None:\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{NUM_EPOCHS} ---\")\n",
    "        train_loss = train_one_epoch(train_loader, model, optimizer, criterion, DEVICE, scaler)\n",
    "        train_losses.append(train_loss)\n",
    "        val_loss = float('inf')\n",
    "        if val_loader is not None:\n",
    "            val_loss = validate_one_epoch(val_loader, model, criterion, DEVICE)\n",
    "            val_losses.append(val_loss)\n",
    "        \n",
    "        save_path = f\"model_epoch_{epoch+1}.pth\"\n",
    "        if val_loss < best_val_loss : # Condition met if val_loader exists and loss improved\n",
    "            if val_loader is not None: # ensure val_loss is from actual validation\n",
    "                 best_val_loss = val_loss\n",
    "                 save_path = \"best_denoising_model.pth\"\n",
    "                 print(f\"Saved new best model with val_loss: {best_val_loss:.4f} to {save_path}\")\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        if val_loader is None: print(f\"Saved model checkpoint to {save_path} (no validation).\")\n",
    "\n",
    "else:\n",
    "    print(\"Training cannot proceed as train_loader is not available.\")\n",
    "\n",
    "print(\"\\nTraining finished!\")\n",
    "\n",
    "if train_losses or val_losses:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    if train_losses: plt.plot(train_losses, label=\"Training Loss\")\n",
    "    if val_losses: plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss (MSE)\"); plt.title(\"Loss Over Epochs\")\n",
    "    plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "# --- Evaluation & Display (mostly unchanged, uses the new loader) ---\n",
    "def display_results(model, data_loader, device, num_samples=1): # Default to 1 sample for large images\n",
    "    if data_loader is None or len(data_loader) == 0:\n",
    "        print(\"Data loader for display is None or empty. Skipping display.\")\n",
    "        return\n",
    "    model.eval().to(device)\n",
    "    data_iter = iter(data_loader)\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
    "    if num_samples == 1: axes = np.array([axes])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            try:\n",
    "                noisy_input, _, ground_truth = next(data_iter)\n",
    "            except StopIteration: print(\"Not enough samples.\"); break\n",
    "            noisy_input = noisy_input.to(device)\n",
    "            single_noisy_input = noisy_input[0:1] # Keep batch dim\n",
    "            single_ground_truth = ground_truth[0].cpu().numpy().squeeze()\n",
    "            denoised_output = model(single_noisy_input)\n",
    "            single_denoised_output = denoised_output[0].cpu().numpy().squeeze()\n",
    "            single_noisy_input_np = single_noisy_input[0].cpu().numpy().squeeze()\n",
    "\n",
    "            all_vals = np.concatenate([\n",
    "                single_noisy_input_np.ravel(), single_denoised_output.ravel(), single_ground_truth.ravel()\n",
    "            ])\n",
    "            vmin = np.percentile(all_vals, 1) \n",
    "            vmax = np.percentile(all_vals, 99)\n",
    "            if vmin >= vmax: vmin, vmax = all_vals.min(), all_vals.max() # Fallback\n",
    "            if vmin == vmax: vmin -= 0.1; vmax += 0.1 # Ensure range for flat data\n",
    "\n",
    "            im = axes[i,0].imshow(single_noisy_input_np,cmap='viridis',vmin=vmin,vmax=vmax)\n",
    "            axes[i,0].set_title(f\"Noisy (Sample {i+1})\"); axes[i,0].axis('off')\n",
    "            im = axes[i,1].imshow(single_denoised_output,cmap='viridis',vmin=vmin,vmax=vmax)\n",
    "            axes[i,1].set_title(f\"Denoised (Sample {i+1})\"); axes[i,1].axis('off')\n",
    "            im = axes[i,2].imshow(single_ground_truth,cmap='viridis',vmin=vmin,vmax=vmax)\n",
    "            axes[i,2].set_title(f\"Ground Truth (Sample {i+1})\"); axes[i,2].axis('off')\n",
    "    if num_samples > 0: fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.6, label='LOS Disp. (m)')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# Load best model for display\n",
    "model_loaded_for_display = False\n",
    "if os.path.exists(\"best_denoising_model.pth\"):\n",
    "    print(\"\\nLoading best validation model for display...\")\n",
    "    model.load_state_dict(torch.load(\"best_denoising_model.pth\", map_location=DEVICE))\n",
    "    model_loaded_for_display = True\n",
    "elif os.path.exists(f\"model_epoch_{NUM_EPOCHS}.pth\"):\n",
    "    print(f\"\\nBest validation model not found. Loading model from last epoch (epoch {NUM_EPOCHS})...\")\n",
    "    model.load_state_dict(torch.load(f\"model_epoch_{NUM_EPOCHS}.pth\", map_location=DEVICE))\n",
    "    model_loaded_for_display = True\n",
    "else:\n",
    "    print(\"\\nNo saved model weights found for display. Using current model state (if any).\")\n",
    "\n",
    "if model_loaded_for_display or NUM_EPOCHS == 0 : # Display if model was loaded or no training was done (initial state)\n",
    "    if test_loader is not None and len(test_loader) > 0:\n",
    "        print(\"\\nDisplaying results from Test Set...\")\n",
    "        display_results(model, test_loader, DEVICE)\n",
    "    elif val_loader is not None and len(val_loader) > 0:\n",
    "        print(\"\\nTest Set empty or unavailable. Displaying results from Validation Set...\")\n",
    "        display_results(model, val_loader, DEVICE)\n",
    "    elif train_loader is not None and len(train_loader) > 0:\n",
    "        print(\"\\nTest and Validation Sets empty or unavailable. Displaying results from Training Set...\")\n",
    "        display_results(model, train_loader, DEVICE)\n",
    "    else:\n",
    "        print(\"All data loaders are empty. Cannot display results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0450c3c-17be-4aea-9a86-5281a843fcdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
