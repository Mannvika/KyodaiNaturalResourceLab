{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad1bcb91-e5ca-4025-b4fd-e1f051002038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "class Noise2NoiseDataset(Dataset):\n",
    "    def __init__(self, size, S_max=5.0, D=50, nu=0.25, cm=1.0, V=1.0,\n",
    "                 random_noise_std=0.56, tropospheric_noise_beta=1.82, tropospheric_noise_scale=1.0,\n",
    "                 total_days=1460, interval_days=49, f_t=-1, orbit_type='ascending'):\n",
    "        self.size = size\n",
    "        self.S_max = S_max\n",
    "        self.D = D\n",
    "        self.nu = nu\n",
    "        self.cm = cm\n",
    "        self.V = V\n",
    "        self.random_noise_std = random_noise_std\n",
    "        self.tropospheric_noise_beta = tropospheric_noise_beta\n",
    "        self.tropospheric_noise_scale = tropospheric_noise_scale\n",
    "        self.total_days = total_days\n",
    "        self.interval_days = interval_days\n",
    "        self.f_t = f_t\n",
    "        self.orbit_type = orbit_type\n",
    "\n",
    "        self.incidence_angle_deg, self.satellite_azimuth_deg = self._get_orbit_geometry()\n",
    "        self.times = self.get_times()\n",
    "        if len(self.times) == 0:\n",
    "            print(f\"Warning: No time steps generated for total_days={total_days}, interval_days={interval_days}. Defaulting total_time to 1.0.\")\n",
    "            self.total_time = 1.0\n",
    "        elif len(self.times) == 1:\n",
    "             self.total_time = self.times[0]\n",
    "        else:\n",
    "            self.total_time = self.times[-1]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.times)\n",
    "\n",
    "    def generate_random_noise(self):\n",
    "        return np.random.normal(loc=0.0, scale=self.random_noise_std, size=self.size)\n",
    "\n",
    "    def generate_tropospheric_noise(self):\n",
    "        noise = np.fft.fft2(np.random.randn(*self.size))\n",
    "        ky = np.fft.fftfreq(self.size[0])\n",
    "        kx = np.fft.fftfreq(self.size[1])\n",
    "        kx, ky = np.meshgrid(kx, ky)\n",
    "        k = np.sqrt(kx**2 + ky**2)\n",
    "        k[0, 0] = 1e-7\n",
    "        power = k ** (-self.tropospheric_noise_beta)\n",
    "        frac_noise = np.fft.ifft2(noise * power).real\n",
    "        std_val = frac_noise.std()\n",
    "        if std_val > 1e-6:\n",
    "            frac_noise = (frac_noise - frac_noise.mean()) / std_val\n",
    "        else:\n",
    "            frac_noise = frac_noise - frac_noise.mean()\n",
    "\n",
    "        return frac_noise * self.tropospheric_noise_scale\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_los_vector(incidence_angle_deg, satellite_azimuth_deg):\n",
    "        incidence_angle_rad = np.deg2rad(incidence_angle_deg)\n",
    "        satellite_azimuth_rad = np.deg2rad(satellite_azimuth_deg)\n",
    "        look_azimuth_rad = satellite_azimuth_rad + np.pi/2\n",
    "\n",
    "        l_east = np.sin(incidence_angle_rad) * np.sin(look_azimuth_rad)\n",
    "        l_north = np.sin(incidence_angle_rad) * np.cos(look_azimuth_rad)\n",
    "        l_up = np.cos(incidence_angle_rad)\n",
    "        return np.array([l_east, l_north, l_up])\n",
    "\n",
    "\n",
    "    def generate_subsidence(self, delta_P):\n",
    "        y, x = np.indices(self.size)\n",
    "        cx, cy = self.size[1] // 2, self.size[0] // 2\n",
    "        r_sq = (x - cx)**2 + (y - cy)**2\n",
    "        r = np.sqrt(r_sq)\n",
    "\n",
    "        factor = (-1 / np.pi) * self.cm * (1 - self.nu) * delta_P * self.V\n",
    "\n",
    "        uz = factor * (self.D / ((r**2 + self.D**2)**(1.5)))\n",
    "        ur = factor * (r / ((r**2 + self.D**2)**(1.5)))\n",
    "\n",
    "        azimuth = np.arctan2(y - cy, x - cx)\n",
    "        ux = ur * np.cos(azimuth)\n",
    "        uy = ur * np.sin(azimuth)\n",
    "\n",
    "        los_vector_calc = Noise2NoiseDataset.calculate_los_vector(self.incidence_angle_deg, self.satellite_azimuth_deg)\n",
    "\n",
    "        simulated_interferogram = (ux * los_vector_calc[0]) + \\\n",
    "                                  (uy * los_vector_calc[1]) + \\\n",
    "                                  (uz * los_vector_calc[2])\n",
    "        return simulated_interferogram\n",
    "\n",
    "    def get_times(self):\n",
    "        if self.total_days < self.interval_days or self.interval_days <= 0:\n",
    "            return np.array([self.total_days if self.total_days > 0 else 1.0])\n",
    "        return np.arange(self.interval_days, self.total_days + 1, self.interval_days)\n",
    "\n",
    "\n",
    "    def _get_clean_subsidence_image(self, t):\n",
    "        delta_P_for_S_max_subsidence = self.S_max * np.pi * self.D**2 / (self.cm * (1 - self.nu) * self.V)\n",
    "\n",
    "        if self.total_time <= 0 : self.total_time = 1.0\n",
    "\n",
    "        current_time_factor = 0.0\n",
    "        if callable(self.f_t):\n",
    "            if len(self.times) > 0:\n",
    "                normalized_t = t\n",
    "                current_time_factor = self.f_t(normalized_t, self.times, self.total_time)\n",
    "            else:\n",
    "                current_time_factor = t / self.total_time if self.total_time > 0 else 0\n",
    "        else:\n",
    "            current_time_factor = t / self.total_time if self.total_time > 0 else 0\n",
    "\n",
    "        delta_P_current = delta_P_for_S_max_subsidence * current_time_factor\n",
    "        return self.generate_subsidence(delta_P=delta_P_current)\n",
    "\n",
    "\n",
    "    def _get_orbit_geometry(self):\n",
    "        if self.orbit_type == 'ascending':\n",
    "            return 40, 15\n",
    "        elif self.orbit_type == 'descending':\n",
    "            return 40, 195\n",
    "        else:\n",
    "            raise ValueError(\"Invalid orbit type. Choose 'ascending' or 'descending'.\")\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_time = self.times[idx]\n",
    "        clean_image = self._get_clean_subsidence_image(current_time)\n",
    "\n",
    "        noise1_random = self.generate_random_noise()\n",
    "        noise1_tropo = self.generate_tropospheric_noise()\n",
    "        noisy_image1 = clean_image + noise1_random + noise1_tropo\n",
    "\n",
    "        noise2_random = self.generate_random_noise()\n",
    "        noise2_tropo = self.generate_tropospheric_noise()\n",
    "        noisy_image2 = clean_image + noise2_random + noise2_tropo\n",
    "\n",
    "        clean_image_tensor = torch.from_numpy(clean_image.copy()).float().unsqueeze(0)\n",
    "        noisy_image1_tensor = torch.from_numpy(noisy_image1.copy()).float().unsqueeze(0)\n",
    "        noisy_image2_tensor = torch.from_numpy(noisy_image2.copy()).float().unsqueeze(0)\n",
    "\n",
    "        return noisy_image1_tensor, noisy_image2_tensor, clean_image_tensor\n",
    "\n",
    "\n",
    "def f_linear(t, times_array, total_time_val):\n",
    "    if total_time_val == 0: return 0\n",
    "    return t / total_time_val\n",
    "\n",
    "def f_log(t, times_array, total_time_val):\n",
    "    if total_time_val == 0: return 0\n",
    "    if t <= 0: t = 1e-6\n",
    "    if total_time_val <=0: total_time_val = 1e-6\n",
    "    \n",
    "    min_time_in_series = times_array[0] if len(times_array)>0 else 1.0\n",
    "\n",
    "    adjusted_t = t - min_time_in_series + 1\n",
    "    adjusted_total_time = total_time_val - min_time_in_series + 1\n",
    "\n",
    "    if adjusted_total_time <= 1:\n",
    "        return 1.0 if t >= total_time_val else 0.0\n",
    "\n",
    "    val = np.log1p(max(0, adjusted_t)) / np.log1p(max(1e-7, adjusted_total_time))\n",
    "    return min(max(0, val), 1.0)\n",
    "\n",
    "\n",
    "IMG_SIZE = (1500, 1500)\n",
    "S_MAX = 5\n",
    "D_DEPTH = 50\n",
    "RANDOM_NOISE_STD = 0.56\n",
    "TROPO_SCALE = 1.0\n",
    "TOTAL_DAYS = 365 * 4\n",
    "INTERVAL_DAYS = 49\n",
    "\n",
    "print(\"Creating datasets...\")\n",
    "dataset_lin_asc = Noise2NoiseDataset(\n",
    "    size=IMG_SIZE, S_max=S_MAX, D=D_DEPTH, random_noise_std=RANDOM_NOISE_STD,\n",
    "    tropospheric_noise_scale=TROPO_SCALE, total_days=TOTAL_DAYS, interval_days=INTERVAL_DAYS,\n",
    "    f_t=-1,\n",
    "    orbit_type='ascending'\n",
    ")\n",
    "print(f\"Linear Ascending: {len(dataset_lin_asc)} samples\")\n",
    "\n",
    "dataset_log_asc = Noise2NoiseDataset(\n",
    "    size=IMG_SIZE, S_max=S_MAX, D=D_DEPTH, random_noise_std=RANDOM_NOISE_STD,\n",
    "    tropospheric_noise_scale=TROPO_SCALE, total_days=TOTAL_DAYS, interval_days=INTERVAL_DAYS,\n",
    "    f_t=f_log,\n",
    "    orbit_type='ascending'\n",
    ")\n",
    "print(f\"Log Ascending: {len(dataset_log_asc)} samples\")\n",
    "\n",
    "dataset_lin_desc = Noise2NoiseDataset(\n",
    "    size=IMG_SIZE, S_max=S_MAX, D=D_DEPTH, random_noise_std=RANDOM_NOISE_STD,\n",
    "    tropospheric_noise_scale=TROPO_SCALE, total_days=TOTAL_DAYS, interval_days=INTERVAL_DAYS,\n",
    "    f_t=-1,\n",
    "    orbit_type='descending'\n",
    ")\n",
    "print(f\"Linear Descending: {len(dataset_lin_desc)} samples\")\n",
    "\n",
    "dataset_log_desc = Noise2NoiseDataset(\n",
    "    size=IMG_SIZE, S_max=S_MAX, D=D_DEPTH, random_noise_std=RANDOM_NOISE_STD,\n",
    "    tropospheric_noise_scale=TROPO_SCALE, total_days=TOTAL_DAYS, interval_days=INTERVAL_DAYS,\n",
    "    f_t=f_log,\n",
    "    orbit_type='descending'\n",
    ")\n",
    "print(f\"Log Descending: {len(dataset_log_desc)} samples\")\n",
    "\n",
    "combined_dataset = ConcatDataset([\n",
    "    dataset_lin_asc, dataset_log_asc,\n",
    "    dataset_lin_desc, dataset_log_desc\n",
    "])\n",
    "print(f\"Total combined samples: {len(combined_dataset)}\")\n",
    "\n",
    "total_samples = len(combined_dataset)\n",
    "indices = list(range(total_samples))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "train_split = int(train_ratio * total_samples)\n",
    "val_split = int(val_ratio * total_samples)\n",
    "\n",
    "train_indices = indices[:train_split]\n",
    "val_indices = indices[train_split : train_split + val_split]\n",
    "test_indices = indices[train_split + val_split:]\n",
    "\n",
    "train_dataset = Subset(combined_dataset, train_indices)\n",
    "val_dataset = Subset(combined_dataset, val_indices)\n",
    "test_dataset = Subset(combined_dataset, test_indices)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=[32, 64, 128]):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        for feature in features:\n",
    "            self.downs.append(self._double_conv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        self.bottleneck = self._double_conv(features[-1], features[-1] * 2)\n",
    "\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2))\n",
    "            self.ups.append(self._double_conv(feature * 2, feature))\n",
    "\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def _double_conv(self, in_c, out_c):\n",
    "        conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        return conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        for down_conv in self.downs:\n",
    "            x = down_conv(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for i in range(0, len(self.ups), 2):\n",
    "            x = self.ups[i](x)\n",
    "            skip_connection = skip_connections[i//2]\n",
    "\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = torch.nn.functional.interpolate(x, size=skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[i+1](concat_skip)\n",
    "\n",
    "        return self.final_conv(x)\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "MODEL_FEATURES = [64, 128, 256, 512]\n",
    "\n",
    "model = SimpleUNet(in_channels=1, out_channels=1, features=MODEL_FEATURES).to(DEVICE)\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 100\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE.type == 'cuda'))\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, criterion, device, scaler):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (noisy1, noisy2, _) in enumerate(loader):\n",
    "        noisy1 = noisy1.to(device)\n",
    "        noisy2 = noisy2.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE.type == 'cuda')):\n",
    "            denoised_output = model(noisy1)\n",
    "            loss = criterion(denoised_output, noisy2)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "             print(f\"Batch {batch_idx}/{len(loader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(loader)\n",
    "    print(f\"End of Epoch, Avg Training Loss: {avg_epoch_loss:.4f}\")\n",
    "    return avg_epoch_loss\n",
    "\n",
    "def validate_one_epoch(loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for noisy1, noisy2, _ in loader:\n",
    "            noisy1 = noisy1.to(device)\n",
    "            noisy2 = noisy2.to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=(DEVICE.type == 'cuda')):\n",
    "                denoised_output = model(noisy1)\n",
    "                loss = criterion(denoised_output, noisy2)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(loader)\n",
    "    print(f\"Validation Avg Loss: {avg_epoch_loss:.4f}\")\n",
    "    return avg_epoch_loss\n",
    "\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{NUM_EPOCHS} ---\")\n",
    "    train_loss = train_one_epoch(train_loader, model, optimizer, criterion, DEVICE, scaler)\n",
    "    val_loss = validate_one_epoch(val_loader, model, criterion, DEVICE)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_denoising_model.pth\")\n",
    "        print(f\"Saved new best model with val_loss: {best_val_loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining finished!\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def display_results(model, data_loader, device, num_samples=3):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    data_iter = iter(data_loader)\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = np.array([axes])\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            try:\n",
    "                noisy_input, _, ground_truth = next(data_iter)\n",
    "            except StopIteration:\n",
    "                print(\"Not enough samples in the loader to display the requested number.\")\n",
    "                break\n",
    "\n",
    "            noisy_input = noisy_input.to(device)\n",
    "            single_noisy_input = noisy_input[0:1]\n",
    "            single_ground_truth = ground_truth[0].cpu().numpy().squeeze()\n",
    "\n",
    "            denoised_output = model(single_noisy_input)\n",
    "            single_denoised_output = denoised_output[0].cpu().numpy().squeeze()\n",
    "            single_noisy_input_np = single_noisy_input[0].cpu().numpy().squeeze()\n",
    "\n",
    "            vmin = min(single_noisy_input_np.min(), single_denoised_output.min(), single_ground_truth.min())\n",
    "            vmax = max(single_noisy_input_np.max(), single_denoised_output.max(), single_ground_truth.max())\n",
    "\n",
    "            im = axes[i, 0].imshow(single_noisy_input_np, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "            axes[i, 0].set_title(f\"Noisy Input (Sample {i+1})\")\n",
    "            axes[i, 0].axis('off')\n",
    "\n",
    "            im = axes[i, 1].imshow(single_denoised_output, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "            axes[i, 1].set_title(f\"Denoised Output (Sample {i+1})\")\n",
    "            axes[i, 1].axis('off')\n",
    "\n",
    "            im = axes[i, 2].imshow(single_ground_truth, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "            axes[i, 2].set_title(f\"Ground Truth (Sample {i+1})\")\n",
    "            axes[i, 2].axis('off')\n",
    "\n",
    "    fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.6, label='LOS Displacement (m)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if best_val_loss != float('inf'):\n",
    "    print(\"\\nLoading best model for display...\")\n",
    "    model.load_state_dict(torch.load(\"best_denoising_model.pth\", map_location=DEVICE))\n",
    "\n",
    "print(\"\\nDisplaying results from Test Set...\")\n",
    "display_results(model, test_loader, DEVICE, num_samples=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
